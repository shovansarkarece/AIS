{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd1871a-5f67-403c-8762-997dce951923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO('yolo11l.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68ba07f7-14b7-4389-b82a-e24a1feb037c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'person',\n",
       " 1: 'bicycle',\n",
       " 2: 'car',\n",
       " 3: 'motorcycle',\n",
       " 4: 'airplane',\n",
       " 5: 'bus',\n",
       " 6: 'train',\n",
       " 7: 'truck',\n",
       " 8: 'boat',\n",
       " 9: 'traffic light',\n",
       " 10: 'fire hydrant',\n",
       " 11: 'stop sign',\n",
       " 12: 'parking meter',\n",
       " 13: 'bench',\n",
       " 14: 'bird',\n",
       " 15: 'cat',\n",
       " 16: 'dog',\n",
       " 17: 'horse',\n",
       " 18: 'sheep',\n",
       " 19: 'cow',\n",
       " 20: 'elephant',\n",
       " 21: 'bear',\n",
       " 22: 'zebra',\n",
       " 23: 'giraffe',\n",
       " 24: 'backpack',\n",
       " 25: 'umbrella',\n",
       " 26: 'handbag',\n",
       " 27: 'tie',\n",
       " 28: 'suitcase',\n",
       " 29: 'frisbee',\n",
       " 30: 'skis',\n",
       " 31: 'snowboard',\n",
       " 32: 'sports ball',\n",
       " 33: 'kite',\n",
       " 34: 'baseball bat',\n",
       " 35: 'baseball glove',\n",
       " 36: 'skateboard',\n",
       " 37: 'surfboard',\n",
       " 38: 'tennis racket',\n",
       " 39: 'bottle',\n",
       " 40: 'wine glass',\n",
       " 41: 'cup',\n",
       " 42: 'fork',\n",
       " 43: 'knife',\n",
       " 44: 'spoon',\n",
       " 45: 'bowl',\n",
       " 46: 'banana',\n",
       " 47: 'apple',\n",
       " 48: 'sandwich',\n",
       " 49: 'orange',\n",
       " 50: 'broccoli',\n",
       " 51: 'carrot',\n",
       " 52: 'hot dog',\n",
       " 53: 'pizza',\n",
       " 54: 'donut',\n",
       " 55: 'cake',\n",
       " 56: 'chair',\n",
       " 57: 'couch',\n",
       " 58: 'potted plant',\n",
       " 59: 'bed',\n",
       " 60: 'dining table',\n",
       " 61: 'toilet',\n",
       " 62: 'tv',\n",
       " 63: 'laptop',\n",
       " 64: 'mouse',\n",
       " 65: 'remote',\n",
       " 66: 'keyboard',\n",
       " 67: 'cell phone',\n",
       " 68: 'microwave',\n",
       " 69: 'oven',\n",
       " 70: 'toaster',\n",
       " 71: 'sink',\n",
       " 72: 'refrigerator',\n",
       " 73: 'book',\n",
       " 74: 'clock',\n",
       " 75: 'vase',\n",
       " 76: 'scissors',\n",
       " 77: 'teddy bear',\n",
       " 78: 'hair drier',\n",
       " 79: 'toothbrush'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_list = model.names \n",
    "class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8676ca61-e090-418e-8e97-cc41e7060044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the video file\n",
    "cap = cv2.VideoCapture('test_videos/6 - Trim.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a049d501-4764-4583-be30-531573410c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 9 cars, 1 truck, 993.2ms\n",
      "Speed: 3.4ms preprocess, 993.2ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 974.5ms\n",
      "Speed: 3.0ms preprocess, 974.5ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 934.5ms\n",
      "Speed: 5.5ms preprocess, 934.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 1043.4ms\n",
      "Speed: 3.0ms preprocess, 1043.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 1136.2ms\n",
      "Speed: 3.0ms preprocess, 1136.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1104.6ms\n",
      "Speed: 4.0ms preprocess, 1104.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 2 trucks, 1060.8ms\n",
      "Speed: 5.6ms preprocess, 1060.8ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 1026.9ms\n",
      "Speed: 3.0ms preprocess, 1026.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1048.2ms\n",
      "Speed: 3.0ms preprocess, 1048.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1122.9ms\n",
      "Speed: 4.0ms preprocess, 1122.9ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 truck, 1040.3ms\n",
      "Speed: 3.0ms preprocess, 1040.3ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 truck, 1040.8ms\n",
      "Speed: 6.0ms preprocess, 1040.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 2 trucks, 976.4ms\n",
      "Speed: 3.0ms preprocess, 976.4ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 truck, 1123.7ms\n",
      "Speed: 3.0ms preprocess, 1123.7ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1247.5ms\n",
      "Speed: 3.5ms preprocess, 1247.5ms inference, 9.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1107.4ms\n",
      "Speed: 4.0ms preprocess, 1107.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 1167.2ms\n",
      "Speed: 8.1ms preprocess, 1167.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 1151.4ms\n",
      "Speed: 2.0ms preprocess, 1151.4ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 922.6ms\n",
      "Speed: 7.6ms preprocess, 922.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 2 trucks, 960.7ms\n",
      "Speed: 4.5ms preprocess, 960.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 truck, 1098.2ms\n",
      "Speed: 5.6ms preprocess, 1098.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 2 trucks, 1115.6ms\n",
      "Speed: 4.0ms preprocess, 1115.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 2 trucks, 1091.1ms\n",
      "Speed: 2.0ms preprocess, 1091.1ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 2 trucks, 1089.3ms\n",
      "Speed: 4.7ms preprocess, 1089.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1127.4ms\n",
      "Speed: 4.6ms preprocess, 1127.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 1038.1ms\n",
      "Speed: 3.6ms preprocess, 1038.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1012.4ms\n",
      "Speed: 4.0ms preprocess, 1012.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 1 truck, 1117.9ms\n",
      "Speed: 3.0ms preprocess, 1117.9ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 1 truck, 1022.1ms\n",
      "Speed: 4.5ms preprocess, 1022.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 2 trucks, 1116.8ms\n",
      "Speed: 4.0ms preprocess, 1116.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 truck, 1108.8ms\n",
      "Speed: 6.1ms preprocess, 1108.8ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 1111.6ms\n",
      "Speed: 2.0ms preprocess, 1111.6ms inference, 10.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 1031.4ms\n",
      "Speed: 5.6ms preprocess, 1031.4ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 1108.0ms\n",
      "Speed: 3.0ms preprocess, 1108.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 980.8ms\n",
      "Speed: 3.5ms preprocess, 980.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 1134.7ms\n",
      "Speed: 2.0ms preprocess, 1134.7ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1201.8ms\n",
      "Speed: 7.6ms preprocess, 1201.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1277.2ms\n",
      "Speed: 6.3ms preprocess, 1277.2ms inference, 13.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1236.7ms\n",
      "Speed: 5.6ms preprocess, 1236.7ms inference, 11.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1191.1ms\n",
      "Speed: 5.5ms preprocess, 1191.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1174.9ms\n",
      "Speed: 8.5ms preprocess, 1174.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1236.5ms\n",
      "Speed: 3.5ms preprocess, 1236.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1150.0ms\n",
      "Speed: 7.6ms preprocess, 1150.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 motorcycle, 1141.3ms\n",
      "Speed: 6.6ms preprocess, 1141.3ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1153.7ms\n",
      "Speed: 3.5ms preprocess, 1153.7ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1213.3ms\n",
      "Speed: 4.7ms preprocess, 1213.3ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1197.9ms\n",
      "Speed: 5.5ms preprocess, 1197.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1149.9ms\n",
      "Speed: 3.5ms preprocess, 1149.9ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1165.0ms\n",
      "Speed: 4.0ms preprocess, 1165.0ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 motorcycle, 1174.4ms\n",
      "Speed: 4.5ms preprocess, 1174.4ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1148.4ms\n",
      "Speed: 7.5ms preprocess, 1148.4ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 motorcycle, 1238.5ms\n",
      "Speed: 6.1ms preprocess, 1238.5ms inference, 10.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 motorcycle, 1220.7ms\n",
      "Speed: 2.5ms preprocess, 1220.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 motorcycle, 1185.9ms\n",
      "Speed: 4.0ms preprocess, 1185.9ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1204.9ms\n",
      "Speed: 3.0ms preprocess, 1204.9ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 motorcycle, 1149.4ms\n",
      "Speed: 5.0ms preprocess, 1149.4ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 motorcycle, 1171.6ms\n",
      "Speed: 3.0ms preprocess, 1171.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 motorcycle, 1 truck, 1187.8ms\n",
      "Speed: 4.0ms preprocess, 1187.8ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 motorcycle, 1141.1ms\n",
      "Speed: 4.5ms preprocess, 1141.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 motorcycle, 1201.4ms\n",
      "Speed: 2.0ms preprocess, 1201.4ms inference, 10.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 motorcycle, 1200.5ms\n",
      "Speed: 5.5ms preprocess, 1200.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 motorcycle, 1096.0ms\n",
      "Speed: 3.5ms preprocess, 1096.0ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 motorcycle, 1183.9ms\n",
      "Speed: 4.6ms preprocess, 1183.9ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 motorcycle, 1213.3ms\n",
      "Speed: 3.5ms preprocess, 1213.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 motorcycle, 1230.9ms\n",
      "Speed: 3.0ms preprocess, 1230.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 motorcycle, 1161.8ms\n",
      "Speed: 9.6ms preprocess, 1161.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 motorcycle, 1178.4ms\n",
      "Speed: 5.6ms preprocess, 1178.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 motorcycle, 1184.6ms\n",
      "Speed: 3.0ms preprocess, 1184.6ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 1181.5ms\n",
      "Speed: 3.3ms preprocess, 1181.5ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 2 trucks, 1178.7ms\n",
      "Speed: 4.0ms preprocess, 1178.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 2 trucks, 1031.2ms\n",
      "Speed: 3.0ms preprocess, 1031.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO('yolo11l.pt')\n",
    "\n",
    "class_list = model.names \n",
    "#class_list\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture('test_videos/6 - Trim.mp4')\n",
    "\n",
    "line_y_red = 430  # Red line position\n",
    "\n",
    "# Dictionary to store object counts by class\n",
    "class_counts = defaultdict(int)\n",
    "\n",
    "# Dictionary to keep track of object IDs that have crossed the line\n",
    "crossed_ids = set()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run YOLO tracking on the frame\n",
    "    results = model.track(frame, persist=True, classes = [1,2,3,5,6,7]) \n",
    "    #print(results)\n",
    "\n",
    "    # Ensure results are not empty\n",
    "    if results[0].boxes.data is not None:\n",
    "        # Get the detected boxes, their class indices, and track IDs\n",
    "        boxes = results[0].boxes.xyxy.cpu()\n",
    "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "        class_indices = results[0].boxes.cls.int().cpu().tolist()\n",
    "        confidences = results[0].boxes.conf.cpu()\n",
    "\n",
    "        cv2.line(frame, (690, line_y_red), (1130, line_y_red), (0, 0, 255), 3)\n",
    "        #cv2.putText(frame, 'Red Line', (690, line_y_red - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        # Loop through each detected object\n",
    "        for box, track_id, class_idx, conf in zip(boxes, track_ids, class_indices, confidences):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            cx = (x1 + x2) // 2  # Calculate the center point\n",
    "            cy = (y1 + y2) // 2            \n",
    "\n",
    "            class_name = class_list[class_idx]\n",
    "\n",
    "            cv2.circle(frame, (cx, cy), 4, (0, 0, 255), -1)\n",
    "            \n",
    "            cv2.putText(frame, f\"ID: {track_id} {class_name}\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2) \n",
    "\n",
    "\n",
    "            # Check if the object has crossed the red line\n",
    "            if cy > line_y_red and track_id not in crossed_ids:\n",
    "                # Mark the object as crossed\n",
    "                crossed_ids.add(track_id)\n",
    "                class_counts[class_name] += 1\n",
    "\n",
    "\n",
    "        # Display the counts on the frame\n",
    "        y_offset = 30\n",
    "        for class_name, count in class_counts.items():\n",
    "            cv2.putText(frame, f\"{class_name}: {count}\", (50, y_offset),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "            y_offset += 30\n",
    "\n",
    "    \n",
    "    \n",
    "    # Show the frame\n",
    "    cv2.imshow(\"YOLO Object Tracking & Counting\", frame)    \n",
    "    \n",
    "    # Exit loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5825c041-6e6e-451a-ab09-67b6b256376a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20bcdcd-dbb2-4116-98af-91d045dcb45c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
